# ğŸ•·ï¸ Projet Web Scrapping avec BeautifulSoup

Un projet de web scrapping dÃ©veloppÃ© en Python utilisant la bibliothÃ¨que BeautifulSoup pour extraire et analyser des donnÃ©es depuis des sites web.

![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)
![BeautifulSoup](https://img.shields.io/badge/BeautifulSoup-4.0+-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

## ğŸ“‹ Description

Ce projet permet d'extraire automatiquement des paroles de chansons depuis des sites web en utilisant les techniques de web scrapping. BeautifulSoup facilite l'analyse du code HTML et l'extraction des paroles qui sont ensuite sauvegardÃ©es au format JSON.

## âœ¨ FonctionnalitÃ©s

- ğŸµ **Extraction de paroles** : RÃ©cupÃ©ration automatique de paroles de chansons depuis le web
- ğŸ” **Analyse HTML** : Parsing et navigation dans la structure HTML des pages
- ğŸ“Š **Traitement des donnÃ©es** : Nettoyage et organisation des paroles extraites
- ğŸ’¾ **Sauvegarde JSON** : Export des rÃ©sultats dans un fichier JSON structurÃ©

## ğŸš€ Installation

### PrÃ©requis

- Python 3.7 ou supÃ©rieur
- pip (gestionnaire de paquets Python)

### Ã‰tapes d'installation

1. **Clonez ce dÃ©pÃ´t :**
```bash
git clone https://github.com/EbroVital/webScraping.git
cd webScraping
```

2. **CrÃ©ez un environnement virtuel (recommandÃ©) :**
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

3. **Installez les dÃ©pendances :**
```bash
pip install beautifulsoup4
pip install requests
```

**OU** utilisez le fichier requirements.txt (si disponible) :
```bash
pip install -r requirements.txt
```

### ğŸ“¦ DÃ©pendances principales

- **beautifulsoup4** : BibliothÃ¨que pour le parsing HTML/XML
- **requests** : Pour effectuer des requÃªtes HTTP

## ğŸ’» Utilisation

### Utilisation basique

```python
from bs4 import BeautifulSoup
import requests

# Effectuer une requÃªte HTTP
url = "https://example.com"
response = requests.get(url)

# Parser le contenu HTML
soup = BeautifulSoup(r.content, 'html.parser')

# Extraire des donnÃ©es
lyrics = soup.find("div", class_="Lyrics__Container-sc-a49d8432-1 fBKwZw")
```

### Lancer le script principal

```bash
python index.py
```


## ğŸ› ï¸ Technologies utilisÃ©es

- **Python** : Langage de programmation
- **BeautifulSoup4** : Parsing et extraction de donnÃ©es HTML/XML
- **Requests** : Gestion des requÃªtes HTTP

## ğŸ“– Exemples d'utilisation

### Extraire tous les liens d'une page

```python
from bs4 import BeautifulSoup
import requests

url = "https://example.com"
response = requests.get(url)
soup = BeautifulSoup(response.content, 'lxml')

# Trouver tous les liens
liens = soup.find_all('a')
for lien in liens:
    print(lien.get('href'))
```


### Sauvegarder les donnÃ©es dans un fichier JSON

```python
import json

urls = get_all_urls()
    
    words = []
    for url in urls :
        lyrics = extract_lyrics(url=url)
        words.extend(lyrics)
    
    with open("data.json", "w") as f :
        json.dump(words, f, indent=4)
```

## âš ï¸ ConsidÃ©rations lÃ©gales et Ã©thiques

- âœ… VÃ©rifiez toujours le fichier `robots.txt` du site avant de scraper
- âœ… Respectez les conditions d'utilisation des sites web
- âœ… Limitez la frÃ©quence de vos requÃªtes pour ne pas surcharger les serveurs
- âœ… Identifiez votre bot avec un User-Agent appropriÃ©
- âŒ Ne scrapez pas de donnÃ©es personnelles sans autorisation

## ğŸ”§ RÃ©solution des problÃ¨mes courants

### Erreur de connexion
```python
# Ajouter un User-Agent
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
response = requests.get(url, headers=headers)
```
## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Pour contribuer :

1. Forkez le projet
2. CrÃ©ez une branche (`git checkout -b feature/AmazingFeature`)
3. Committez vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Poussez vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

## ğŸ“ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ“š Ressources utiles

- [Documentation BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [Documentation Requests](https://requests.readthedocs.io/)
- [Guide du Web Scraping Ã©thique](https://www.scrapehero.com/web-scraping-laws/)

---

â­ Si ce projet vous a Ã©tÃ© utile, n'hÃ©sitez pas Ã  lui donner une Ã©toile sur GitHub !
